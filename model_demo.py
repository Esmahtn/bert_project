import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pandas as pd

# ğŸš¨ GÃœNCEL KLASÃ–R YOLU: Ä°lk turda eÄŸitilen 5-epoch Law-EQA modeli.
BEST_MODEL_PATH = "./trained-models/yg_eqa"

# Etiket HaritasÄ±
id2label = {0: "YUKSEK_RISK", 1: "ORTA_RISK", 2: "RISKSIZ"}

# 1. Kalitatif Test Edilecek SÃ¶zleÅŸme Maddeleri (AynÄ± Ã–rnekler)
test_sentences = [
    # YÃœKSEK RÄ°SK Ã–rnekleri
    {"text": "Bu sÃ¶zleÅŸme, karÅŸÄ± tarafÄ±n yazÄ±lÄ± izni olmaksÄ±zÄ±n tarafÄ±mÄ±zca herhangi bir sebeple derhal ve tek taraflÄ± olarak feshedilebilir.", "expected_label": "YUKSEK_RISK"},
    {"text": "Tazminat taleplerinde, ÅŸirketin sorumluluÄŸu yalnÄ±zca sÃ¶zleÅŸme bedelinin %5'i ile sÄ±nÄ±rlÄ±dÄ±r ve bu sÄ±nÄ±r aÅŸÄ±lamaz.", "expected_label": "YUKSEK_RISK"},
    
    # ORTA RÄ°SK Ã–rnekleri
    {"text": "Gizlilik sÃ¼resi, sÃ¶zleÅŸme sona erdikten sonra 1 yÄ±l olarak belirlenmiÅŸtir, ancak bu sÃ¼re Ã¶zel bir durum halinde uzatÄ±labilir.", "expected_label": "ORTA_RISK"},
    {"text": "Gecikme durumunda cezai ÅŸart uygulanÄ±r, ancak karÅŸÄ± tarafÄ±n mÃ¼cbir sebep ispatlamasÄ± halinde ceza kaldÄ±rÄ±lÄ±r.", "expected_label": "ORTA_RISK"},
    
    # RÄ°SKSÄ°Z Ã–rnekleri
    {"text": "Taraflar arasÄ±ndaki tebligatlar, PTT aracÄ±lÄ±ÄŸÄ± ile madde 2'de belirtilen resmi adreslere gÃ¶nderilecektir.", "expected_label": "RISKSIZ"},
    {"text": "Ä°ÅŸbu sÃ¶zleÅŸme 10 maddeden oluÅŸmaktadÄ±r ve tÃ¼m maddeler taraflarca tam olarak okunmuÅŸ ve kabul edilmiÅŸtir.", "expected_label": "RISKSIZ"},
]

def predict_risk_level(text):
    """Verilen metin iÃ§in risk seviyesini ve gÃ¼ven skorunu tahmin eder."""
    
    # Model ve Tokenizer yÃ¼kleniyor
    try:
        tokenizer = AutoTokenizer.from_pretrained(BEST_MODEL_PATH)
        model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_PATH)
    except Exception as e:
        # EÄŸer model yÃ¼klenemezse hata ver
        return f"Model YÃ¼kleme HatasÄ±: {BEST_MODEL_PATH} yolunda model bulunamadÄ± veya yÃ¼klenemedi. Hata: {e}"

    # Metnin token haline getirilmesi
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
    
    # Tahmin yapÄ±lmasÄ±
    with torch.no_grad():
        logits = model(**inputs).logits
    
    # Logitleri olasÄ±lÄ±ÄŸa Ã§evirme (Softmax)
    probabilities = torch.softmax(logits, dim=1)
    
    # En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±fÄ± bulma
    predicted_class_id = torch.argmax(probabilities).item()
    predicted_label = id2label[predicted_class_id]
    
    # GÃ¼ven Skorunu hesaplama (%)
    confidence_score = probabilities[0][predicted_class_id].item() * 100
    
    return predicted_label, confidence_score

def print_results(results):
    """Tahmin sonuÃ§larÄ±nÄ± rapor formatÄ±nda yazdÄ±rÄ±r."""
    
    print("\n" + "="*90)
    print("ğŸ”¬ TABLO 4: LAW-EQA (5 Epoch / yg_eqa) KALÄ°TATÄ°F ANALÄ°ZÄ°")
    print(f"ğŸ“‰ Model Skoru: F1 ~0.8644 (Ä°lk Tur Sonucu)")
    print("="*90)
    
    header = f"{'Madde TanÄ±mÄ±':<50} | {'Beklenen Etiket':<15} | {'Model Tahmini':<15} | {'GÃ¼ven Skoru':<10}"
    print(header)
    print("-" * 90)
    
    for item in results:
        madde_tanimi = item['text'][:47] + "..." if len(item['text']) > 50 else item['text']
        
        if item['predicted_label'] == item['expected_label']:
            tahmin_str = f"âœ… {item['predicted_label']}"
        else:
            tahmin_str = f"âŒ {item['predicted_label']}"

        output_line = (
            f"{madde_tanimi:<50} | "
            f"{item['expected_label']:<15} | "
            f"{tahmin_str:<15} | "
            f"{item['confidence_score']:.1f} %"
        )
        print(output_line)
        
    print("-" * 90)


if __name__ == "__main__":
    results = []
    
    print(f"Law-EQA (5 Epoch) modeli yÃ¼kleniyor ve kalitatif analiz yapÄ±lÄ±yor (Yol: {BEST_MODEL_PATH})...")
    
    for sentence in test_sentences:
        prediction_result = predict_risk_level(sentence["text"])
        
        if isinstance(prediction_result, str) and "Hata" in prediction_result:
            print(prediction_result)
            break
            
        predicted_label, confidence_score = prediction_result
        
        results.append({
            "text": sentence["text"],
            "expected_label": sentence["expected_label"],
            "predicted_label": predicted_label,
            "confidence_score": confidence_score
        })
    
    if results:
        print_results(results)