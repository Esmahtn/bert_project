import sys
import os
import shutil
import numpy as np
import torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    DataCollatorWithPadding
)
import evaluate

# âš ï¸ Ã–N KOÅULLAR:
# 'dataset-v1-train.csv' ve 'datase-v1-test.csv' dosyalarÄ± bu kod ile aynÄ± klasÃ¶rde olmalÄ±dÄ±r.
# Gerekli kÃ¼tÃ¼phaneler (transformers, datasets, evaluate, numpy) yÃ¼klÃ¼ olmalÄ±dÄ±r.

# 1ï¸âƒ£ KarÅŸÄ±laÅŸtÄ±rÄ±lacak Modeller Listesi
MODEL_LIST = [
    {"name": "Legal-BERT", "path": "msbayindir/legal-turkish-bert-base-cased", "alias": "msb_legal"},
    {"name": "Law-Classification", "path": "muhammtcelik/turkish-bert-law-classification", "alias": "mc_law_cls"},
    {"name": "NER-Legal", "path": "farnazzeidi/ner-legalturk-bert-model", "alias": "fz_ner"},
    {"name": "Law-EQA", "path": "yeniguno/turkish-law-eqa-bert-finetuned", "alias": "yg_eqa"},
]

# 2ï¸âƒ£ Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme
files = {
    "train": "dataset-v1-train.csv", 
    "test": "datase-v1-test.csv"
}
try:
    dataset = load_dataset("csv", data_files=files)
except FileNotFoundError:
    print("ğŸš¨ HATA: Veri setleri (dataset-v1-train.csv veya datase-v1-test.csv) bulunamadÄ±.")
    sys.exit(1)

# Etiket HaritasÄ± (Risk SÄ±nÄ±flandÄ±rma GÃ¶revimiz)
id2label = {0: "YUKSEK_RISK", 1: "ORTA_RISK", 2: "RISKSIZ"}
label2id = {"YUKSEK_RISK": 0, "ORTA_RISK": 1, "RISKSIZ": 2}

# 3ï¸âƒ£ Metrikler
acc = evaluate.load("accuracy")
f1 = evaluate.load("f1")

def compute_metrics(eval_pred):
    """EÄŸitim metriklerini hesaplar: Accuracy ve AÄŸÄ±rlÄ±klÄ± F1."""
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=1)
    accuracy = acc.compute(predictions=preds, references=labels)["accuracy"]
    # AÄŸÄ±rlÄ±klÄ± F1 skoru, dengesiz sÄ±nÄ±flar iÃ§in kritik Ã¶neme sahiptir.
    f1w = f1.compute(predictions=preds, references=labels, average="weighted")["f1"]
    return {"accuracy": accuracy, "f1_weighted": f1w}

# Cihaz AyarÄ±
device = "cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu")

def train_and_evaluate_model(model_info, dataset):
    """Belirtilen modeli fine-tuning eder ve test eder."""
    model_path = model_info["path"]
    model_alias = model_info["alias"]
    output_dir = f"./results-{model_alias}"
    save_path = f"./trained-models/{model_alias}"

    print(f"\n=======================================================")
    print(f"ğŸš€ BAÅLANIYOR: {model_info['name']} ({model_path})")
    print(f"=======================================================")

    # Tokenizer yÃ¼kleme
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    
    # Ã–n Ä°ÅŸleme fonksiyonu
    def preprocess_function(examples):
        return tokenizer(examples["text"], truncation=True, max_length=256)

    # Veri setini token haline getirme
    tokenized_datasets = dataset.map(preprocess_function, batched=True)
    
    # ğŸš¨ Ã–NEMLÄ° DÃœZELTME: ignore_mismatched_sizes=True ekleniyor.
    # Bu, eski modelin 180 veya 23 sÄ±nÄ±flÄ±k Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± atÄ±p yeni, 3 sÄ±nÄ±flÄ±k katman oluÅŸturur.
    model = AutoModelForSequenceClassification.from_pretrained(
        model_path,
        num_labels=3,
        id2label=id2label,
        label2id=label2id,
        ignore_mismatched_sizes=True 
    )
    model.to(device)
    
    # EÄŸitim AyarlarÄ±
    args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=5,  # KarÅŸÄ±laÅŸtÄ±rma iÃ§in yeterli bir epoch sayÄ±sÄ±.
        per_device_train_batch_size=16, 
        per_device_eval_batch_size=16,
        learning_rate=3e-5,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="f1_weighted",
        greater_is_better=True,
        logging_steps=10,
        fp16=torch.cuda.is_available(),
        report_to=["none"] # RaporlamayÄ± devre dÄ±ÅŸÄ± bÄ±rakÄ±yoruz.
    )

    collator = DataCollatorWithPadding(tokenizer=tokenizer)

    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=tokenized_datasets["train"],
        eval_dataset=tokenized_datasets["test"],
        tokenizer=tokenizer,
        data_collator=collator,
        compute_metrics=compute_metrics
    )

    # EÄŸitimi BaÅŸlat
    trainer.train()

    # Modeli Kaydet
    os.makedirs(save_path, exist_ok=True)
    trainer.save_model(save_path)
    tokenizer.save_pretrained(save_path)
    print(f"âœ… Model kaydedildi: {save_path}")

    # Test/DeÄŸerlendirme
    print("ğŸ” Model test veri seti Ã¼zerinde deÄŸerlendiriliyor...")
    evaluation_results = trainer.evaluate()
    
    # GeÃ§ici Ã§Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ sil
    shutil.rmtree(output_dir, ignore_errors=True)
    
    return evaluation_results

# 4ï¸âƒ£ TÃ¼m Modelleri EÄŸitme ve SonuÃ§larÄ± Toplama
if __name__ == "__main__":
    all_results = {}
    
    # ğŸ“ TÃ¼m eÄŸitilmiÅŸ modelleri tutacak ana klasÃ¶rÃ¼ oluÅŸtur
    os.makedirs("./trained-models", exist_ok=True)

    for model_info in MODEL_LIST:
        try:
            results = train_and_evaluate_model(model_info, dataset)
            all_results[model_info["name"]] = {
                "Accuracy": results.get("eval_accuracy", 0),
                "F1_Weighted": results.get("eval_f1_weighted", 0),
                "Loss": results.get("eval_loss", float('inf'))
            }
        except Exception as e:
            print(f"âŒ KRÄ°TÄ°K HATA OLUÅTU ({model_info['name']}): {e}")
            all_results[model_info["name"]] = {"Error": str(e)}

    # 5ï¸âƒ£ KarÅŸÄ±laÅŸtÄ±rma SonuÃ§larÄ±nÄ± YazdÄ±rma (Raporun Ana Verisi)
    print("\n\n=======================================================")
    print("ğŸ† NÄ°HAÄ° KARÅILAÅTIRMALI PERFORMANS Ã–ZETÄ° (TEST VERÄ°SÄ°)")
    print("=======================================================")
    print(f"{'Model AdÄ±':<25} | {'Accuracy':<10} | {'F1 Weighted':<15} | {'Loss':<10}")
    print("-" * 65)

    best_f1 = -1
    best_model = ""

    for name, metrics in all_results.items():
        if "Error" in metrics:
            print(f"{name:<25} | {'HATA':<10} | {metrics['Error']}")
            continue
            
        acc_str = f"{metrics['Accuracy']:.4f}"
        f1_str = f"{metrics['F1_Weighted']:.4f}"
        loss_str = f"{metrics['Loss']:.4f}"
        
        print(f"{name:<25} | {acc_str:<10} | {f1_str:<15} | {loss_str:<10}")

        if metrics['F1_Weighted'] > best_f1:
            best_f1 = metrics['F1_Weighted']
            best_model = name

    print("\n-------------------------------------------------------")
    print(f"ğŸ¥‡ EN Ä°YÄ° MODEL (F1 Skoru): {best_model} ({best_f1:.4f})")
    print("-------------------------------------------------------")